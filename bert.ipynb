{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6842cd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (4.57.3)\n",
      "Requirement already satisfied: datasets in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (4.4.1)\n",
      "Requirement already satisfied: accelerate in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (1.12.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from transformers) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from httpx<1.0.0->datasets) (4.12.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from accelerate) (7.1.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from accelerate) (2.9.1+cu130)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from requests->transformers) (2.6.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from torch>=2.0.0->accelerate) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install transformers datasets accelerate scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c779651",
   "metadata": {},
   "source": [
    "## BERT Baseline for GoEmotions Classification (27 Labels)\n",
    "This notebook trains a baseline BERT model on the GoEmotions dataset with all 27 original emotion labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b96c3c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce RTX 4080 SUPER\n"
     ]
    }
   ],
   "source": [
    "#check if cuda is available\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dcf0af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b9f202",
   "metadata": {},
   "source": [
    "### Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e300e550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9264167112194f07a1aa81efd5e022b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xiang\\miniconda3\\envs\\cis5300\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\xiang\\.cache\\huggingface\\hub\\datasets--google-research-datasets--go_emotions. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4efb6f53f8bf4f77a389f96a31edfcbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/2.77M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "083c7d9373ce4b6fb20ce85c6e01f506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/350k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2d0a0d089724556a166ee5df3cc74a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/347k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd35c33ca4754898b8cd5f8ce91743aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/43410 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9d8ebbe800d4a9ca7e8fbb5186ddd44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/5426 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d66228416b2a4eaaadbf2217551f7398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/5427 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes - Train: 43410, Val: 5426, Test: 5427\n",
      "\n",
      "Number of labels: 28\n",
      "Labels: ['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']\n",
      "\n",
      "Label distribution in training set:\n",
      "  admiration: 4130 (9.5%)\n",
      "  amusement: 2328 (5.4%)\n",
      "  anger: 1567 (3.6%)\n",
      "  annoyance: 2470 (5.7%)\n",
      "  approval: 2939 (6.8%)\n",
      "  caring: 1087 (2.5%)\n",
      "  confusion: 1368 (3.2%)\n",
      "  curiosity: 2191 (5.0%)\n",
      "  desire: 641 (1.5%)\n",
      "  disappointment: 1269 (2.9%)\n",
      "  disapproval: 2022 (4.7%)\n",
      "  disgust: 793 (1.8%)\n",
      "  embarrassment: 303 (0.7%)\n",
      "  excitement: 853 (2.0%)\n",
      "  fear: 596 (1.4%)\n",
      "  gratitude: 2662 (6.1%)\n",
      "  grief: 77 (0.2%)\n",
      "  joy: 1452 (3.3%)\n",
      "  love: 2086 (4.8%)\n",
      "  nervousness: 164 (0.4%)\n",
      "  optimism: 1581 (3.6%)\n",
      "  pride: 111 (0.3%)\n",
      "  realization: 1110 (2.6%)\n",
      "  relief: 153 (0.4%)\n",
      "  remorse: 545 (1.3%)\n",
      "  sadness: 1326 (3.1%)\n",
      "  surprise: 1060 (2.4%)\n",
      "  neutral: 14219 (32.8%)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the GoEmotions dataset from Hugging Face\n",
    "dataset = load_dataset(\"google-research-datasets/go_emotions\", \"simplified\")\n",
    "\n",
    "# Define all 27 GoEmotions labels (+ neutral = 28, but the dataset has 27 unique emotions)\n",
    "LABELS = [\n",
    "    'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring',\n",
    "    'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval',\n",
    "    'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief',\n",
    "    'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization',\n",
    "    'relief', 'remorse', 'sadness', 'surprise', 'neutral'\n",
    "]\n",
    "NUM_LABELS = len(LABELS)\n",
    "\n",
    "# Convert dataset to DataFrames\n",
    "def convert_to_df(split):\n",
    "    data = dataset[split]\n",
    "    rows = []\n",
    "    for i in range(len(data)):\n",
    "        text = data[i]['text']\n",
    "        label_ids = data[i]['labels']\n",
    "        # Create multi-hot encoding\n",
    "        label_vec = [1 if j in label_ids else 0 for j in range(NUM_LABELS)]\n",
    "        rows.append([text] + label_vec)\n",
    "    return pd.DataFrame(rows, columns=['text'] + LABELS)\n",
    "\n",
    "train_df = convert_to_df('train')\n",
    "val_df = convert_to_df('validation')\n",
    "test_df = convert_to_df('test')\n",
    "\n",
    "print(f\"Dataset sizes - Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")\n",
    "print(f\"\\nNumber of labels: {NUM_LABELS}\")\n",
    "print(f\"Labels: {LABELS}\")\n",
    "\n",
    "print(\"\\nLabel distribution in training set:\")\n",
    "for label in LABELS:\n",
    "    count = train_df[label].sum()\n",
    "    pct = count / len(train_df) * 100\n",
    "    print(f\"  {label}: {count} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1993e4",
   "metadata": {},
   "source": [
    "### Create Dataset Class and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea28a6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batches: 2714\n",
      "Validation batches: 340\n",
      "Test batches: 340\n"
     ]
    }
   ],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=128):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.labels = LABELS\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.data.loc[idx, 'text'])\n",
    "        labels = self.data.loc[idx, self.labels].values.astype(float)\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(labels, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = EmotionDataset(train_df, tokenizer)\n",
    "val_dataset = EmotionDataset(val_df, tokenizer)\n",
    "test_dataset = EmotionDataset(test_df, tokenizer)\n",
    "\n",
    "# Create dataloaders\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaebd49",
   "metadata": {},
   "source": [
    "### Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20b09583",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on cuda\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained BERT model for multi-label classification\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=NUM_LABELS,\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "# Setup optimizer and scheduler\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 2e-5\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "print(f\"Model loaded on {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16783906",
   "metadata": {},
   "source": [
    "### Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b16efad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, device, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            \n",
    "            total_loss += outputs.loss.item()\n",
    "            \n",
    "            # Apply sigmoid and threshold\n",
    "            probs = torch.sigmoid(outputs.logits)\n",
    "            preds = (probs > threshold).float()\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    f1_micro = f1_score(all_labels, all_preds, average='micro')\n",
    "    f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
    "    \n",
    "    return {\n",
    "        'loss': total_loss / len(dataloader),\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'predictions': all_preds,\n",
    "        'labels': all_labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755f9108",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd26a0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Epoch 1/3\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2714/2714 [03:24<00:00, 13.29it/s]\n",
      "Training: 100%|██████████| 2714/2714 [03:24<00:00, 13.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 340/340 [00:09<00:00, 34.07it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0918\n",
      "Validation F1 (micro): 0.5123\n",
      "Validation F1 (macro): 0.2567\n",
      "Saved best model!\n",
      "\n",
      "==================================================\n",
      "Epoch 2/3\n",
      "==================================================\n",
      "Saved best model!\n",
      "\n",
      "==================================================\n",
      "Epoch 2/3\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2714/2714 [03:09<00:00, 14.34it/s]\n",
      "Training: 100%|██████████| 2714/2714 [03:09<00:00, 14.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 340/340 [00:10<00:00, 32.29it/s]\n",
      "Evaluating: 100%|██████████| 340/340 [00:10<00:00, 32.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0847\n",
      "Validation F1 (micro): 0.5686\n",
      "Validation F1 (macro): 0.3805\n",
      "Saved best model!\n",
      "\n",
      "==================================================\n",
      "Epoch 3/3\n",
      "==================================================\n",
      "Saved best model!\n",
      "\n",
      "==================================================\n",
      "Epoch 3/3\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2714/2714 [03:10<00:00, 14.22it/s]\n",
      "Training: 100%|██████████| 2714/2714 [03:10<00:00, 14.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 340/340 [00:10<00:00, 33.33it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0848\n",
      "Validation F1 (micro): 0.5748\n",
      "Validation F1 (macro): 0.4071\n",
      "Saved best model!\n",
      "\n",
      "Best Validation F1 (macro): 0.4071\n",
      "Saved best model!\n",
      "\n",
      "Best Validation F1 (macro): 0.4071\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "best_f1 = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scheduler, device)\n",
    "    print(f\"Training Loss: {train_loss:.4f}\")\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    val_results = evaluate(model, val_loader, device)\n",
    "    print(f\"Validation Loss: {val_results['loss']:.4f}\")\n",
    "    print(f\"Validation F1 (micro): {val_results['f1_micro']:.4f}\")\n",
    "    print(f\"Validation F1 (macro): {val_results['f1_macro']:.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_results['f1_macro'] > best_f1:\n",
    "        best_f1 = val_results['f1_macro']\n",
    "        torch.save(model.state_dict(), 'best_bert_model.pt')\n",
    "        print(\"Saved best model!\")\n",
    "\n",
    "print(f\"\\nBest Validation F1 (macro): {best_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ed9578",
   "metadata": {},
   "source": [
    "### Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48c80d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 340/340 [00:11<00:00, 30.40it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "TEST SET RESULTS\n",
      "==================================================\n",
      "Test Loss: 0.0835\n",
      "Test F1 (micro): 0.5859\n",
      "Test F1 (macro): 0.4194\n",
      "\n",
      "Detailed Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.70      0.71      0.70       504\n",
      "     amusement       0.79      0.84      0.81       264\n",
      "         anger       0.61      0.41      0.49       198\n",
      "     annoyance       0.62      0.10      0.17       320\n",
      "      approval       0.65      0.30      0.41       351\n",
      "        caring       0.56      0.33      0.41       135\n",
      "     confusion       0.60      0.29      0.39       153\n",
      "     curiosity       0.58      0.43      0.49       284\n",
      "        desire       0.72      0.37      0.49        83\n",
      "disappointment       0.62      0.05      0.10       151\n",
      "   disapproval       0.50      0.28      0.36       267\n",
      "       disgust       0.83      0.31      0.45       123\n",
      " embarrassment       0.00      0.00      0.00        37\n",
      "    excitement       0.80      0.23      0.36       103\n",
      "          fear       0.73      0.67      0.70        78\n",
      "     gratitude       0.94      0.91      0.92       352\n",
      "         grief       0.00      0.00      0.00         6\n",
      "           joy       0.72      0.53      0.61       161\n",
      "          love       0.80      0.83      0.82       238\n",
      "   nervousness       0.00      0.00      0.00        23\n",
      "      optimism       0.71      0.46      0.56       186\n",
      "         pride       0.00      0.00      0.00        16\n",
      "   realization       0.69      0.06      0.11       145\n",
      "        relief       0.00      0.00      0.00        11\n",
      "       remorse       0.61      0.71      0.66        56\n",
      "       sadness       0.71      0.42      0.53       156\n",
      "      surprise       0.64      0.50      0.56       141\n",
      "       neutral       0.74      0.57      0.64      1787\n",
      "\n",
      "     micro avg       0.72      0.49      0.59      6329\n",
      "     macro avg       0.57      0.37      0.42      6329\n",
      "  weighted avg       0.69      0.49      0.55      6329\n",
      "   samples avg       0.56      0.52      0.53      6329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load best model and evaluate on test set\n",
    "model.load_state_dict(torch.load('best_bert_model.pt'))\n",
    "\n",
    "test_results = evaluate(model, test_loader, device)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"TEST SET RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Test Loss: {test_results['loss']:.4f}\")\n",
    "print(f\"Test F1 (micro): {test_results['f1_micro']:.4f}\")\n",
    "print(f\"Test F1 (macro): {test_results['f1_macro']:.4f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(\n",
    "    test_results['labels'], \n",
    "    test_results['predictions'], \n",
    "    target_names=LABELS,\n",
    "    zero_division=0\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17965d96",
   "metadata": {},
   "source": [
    "### Test with Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "654697ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Predictions:\n",
      "============================================================\n",
      "\n",
      "Text: I'm so happy today! Everything is going great!\n",
      "Predicted: ['admiration', 'joy']\n",
      "Top 5 Probabilities: joy:0.80, admiration:0.32, excitement:0.14, gratitude:0.05, approval:0.03\n",
      "\n",
      "Text: This makes me so angry, I can't believe it!\n",
      "Predicted: ['anger']\n",
      "Top 5 Probabilities: anger:0.80, annoyance:0.27, disgust:0.04, disappointment:0.02, admiration:0.02\n",
      "\n",
      "Text: I'm really scared about what might happen.\n",
      "Predicted: ['fear']\n",
      "Top 5 Probabilities: fear:0.75, nervousness:0.08, disgust:0.04, neutral:0.04, sadness:0.04\n",
      "\n",
      "Text: That's disgusting, I hate it.\n",
      "Predicted: ['disgust']\n",
      "Top 5 Probabilities: disgust:0.72, anger:0.16, annoyance:0.14, fear:0.09, disapproval:0.06\n",
      "\n",
      "Text: I feel so sad and lonely.\n",
      "Predicted: ['sadness']\n",
      "Top 5 Probabilities: sadness:0.85, disappointment:0.14, remorse:0.04, neutral:0.04, fear:0.03\n",
      "\n",
      "Text: Wow, I didn't expect that at all!\n",
      "Predicted: ['surprise']\n",
      "Top 5 Probabilities: surprise:0.84, excitement:0.12, realization:0.05, neutral:0.04, admiration:0.04\n",
      "\n",
      "Text: Thank you so much, you're amazing!\n",
      "Predicted: ['admiration', 'gratitude']\n",
      "Top 5 Probabilities: gratitude:0.95, admiration:0.70, joy:0.03, approval:0.02, excitement:0.02\n",
      "\n",
      "Text: I'm curious about how this works.\n",
      "Predicted: ['curiosity']\n",
      "Top 5 Probabilities: curiosity:0.78, confusion:0.07, neutral:0.06, admiration:0.03, gratitude:0.02\n",
      "\n",
      "Text: I love you so much!\n",
      "Predicted: ['love']\n",
      "Top 5 Probabilities: love:0.95, joy:0.04, admiration:0.03, neutral:0.02, approval:0.02\n"
     ]
    }
   ],
   "source": [
    "def predict_emotions(text, model, tokenizer, threshold=0.3):\n",
    "    \"\"\"Predict emotions for a single text.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=128,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=encoding['input_ids'].to(device),\n",
    "            attention_mask=encoding['attention_mask'].to(device)\n",
    "        )\n",
    "        probs = torch.sigmoid(outputs.logits).cpu().numpy()[0]\n",
    "    \n",
    "    results = {label: prob for label, prob in zip(LABELS, probs)}\n",
    "    predicted = [label for label, prob in results.items() if prob > threshold]\n",
    "    \n",
    "    return results, predicted\n",
    "\n",
    "# Test with sample texts\n",
    "sample_texts = [\n",
    "    \"I'm so happy today! Everything is going great!\",\n",
    "    \"This makes me so angry, I can't believe it!\",\n",
    "    \"I'm really scared about what might happen.\",\n",
    "    \"That's disgusting, I hate it.\",\n",
    "    \"I feel so sad and lonely.\",\n",
    "    \"Wow, I didn't expect that at all!\",\n",
    "    \"Thank you so much, you're amazing!\",\n",
    "    \"I'm curious about how this works.\",\n",
    "    \"I love you so much!\"\n",
    "]\n",
    "\n",
    "print(\"Sample Predictions:\")\n",
    "print(\"=\"*60)\n",
    "for text in sample_texts:\n",
    "    probs, predicted = predict_emotions(text, model, tokenizer)\n",
    "    print(f\"\\nText: {text}\")\n",
    "    print(f\"Predicted: {predicted if predicted else ['neutral']}\")\n",
    "    # Only show top 5 emotions by probability\n",
    "    top_probs = sorted(probs.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    print(f\"Top 5 Probabilities: {', '.join([f'{k}:{v:.2f}' for k, v in top_probs])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cis5300",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
