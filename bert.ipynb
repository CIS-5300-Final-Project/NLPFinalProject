{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6842cd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (1.7.2)\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from transformers) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from transformers) (25.0)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Downloading pyyaml-6.0.3-cp313-cp313-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2025.11.3-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
      "Collecting requests (from transformers)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Downloading pyarrow-22.0.0-cp313-cp313-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from datasets) (2.3.3)\n",
      "Collecting httpx<1.0.0 (from datasets)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.6.0-cp313-cp313-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.19 (from datasets)\n",
      "  Downloading multiprocess-0.70.18-py313-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohttp-3.13.2-cp313-cp313-win_amd64.whl.metadata (8.4 kB)\n",
      "Collecting anyio (from httpx<1.0.0->datasets)\n",
      "  Downloading anyio-4.12.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting certifi (from httpx<1.0.0->datasets)\n",
      "  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1.0.0->datasets)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx<1.0.0->datasets)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1.0.0->datasets)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from accelerate) (7.1.3)\n",
      "Collecting torch>=2.0.0 (from accelerate)\n",
      "  Downloading torch-2.9.1-cp313-cp313-win_amd64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading frozenlist-1.8.0-cp313-cp313-win_amd64.whl.metadata (21 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading multidict-6.7.0-cp313-cp313-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading propcache-0.4.1-cp313-cp313-win_amd64.whl.metadata (14 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading yarl-1.22.0-cp313-cp313-win_amd64.whl.metadata (77 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->transformers)\n",
      "  Downloading charset_normalizer-3.4.4-cp313-cp313-win_amd64.whl.metadata (38 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
      "  Downloading urllib3-2.6.1-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting sympy>=1.13.3 (from torch>=2.0.0->accelerate)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch>=2.0.0->accelerate)\n",
      "  Downloading networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jinja2 (from torch>=2.0.0->accelerate)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from torch>=2.0.0->accelerate) (80.9.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=2.0.0->accelerate)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=2.0.0->accelerate)\n",
      "  Downloading markupsafe-3.0.3-cp313-cp313-win_amd64.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\xiang\\miniconda3\\envs\\cis5300\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "   ---------------------------------------- 0.0/12.0 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 6.3/12.0 MB 34.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.0/12.0 MB 44.8 MB/s  0:00:00\n",
      "Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "   ---------------------------------------- 0.0/566.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 566.1/566.1 kB 36.1 MB/s  0:00:00\n",
      "Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.7/2.7 MB 63.9 MB/s  0:00:00\n",
      "Downloading datasets-4.4.1-py3-none-any.whl (511 kB)\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Downloading fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading multiprocess-0.70.18-py313-none-any.whl (151 kB)\n",
      "Downloading accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
      "Downloading aiohttp-3.13.2-cp313-cp313-win_amd64.whl (452 kB)\n",
      "Downloading multidict-6.7.0-cp313-cp313-win_amd64.whl (45 kB)\n",
      "Downloading yarl-1.22.0-cp313-cp313-win_amd64.whl (86 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Downloading frozenlist-1.8.0-cp313-cp313-win_amd64.whl (43 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading propcache-0.4.1-cp313-cp313-win_amd64.whl (40 kB)\n",
      "Downloading pyarrow-22.0.0-cp313-cp313-win_amd64.whl (28.0 MB)\n",
      "   ---------------------------------------- 0.0/28.0 MB ? eta -:--:--\n",
      "   -------------------------- ------------- 18.9/28.0 MB 89.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 28.0/28.0 MB 78.0 MB/s  0:00:00\n",
      "Downloading pyyaml-6.0.3-cp313-cp313-win_amd64.whl (154 kB)\n",
      "Downloading regex-2025.11.3-cp313-cp313-win_amd64.whl (277 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp313-cp313-win_amd64.whl (107 kB)\n",
      "Downloading urllib3-2.6.1-py3-none-any.whl (131 kB)\n",
      "Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl (341 kB)\n",
      "Downloading torch-2.9.1-cp313-cp313-win_amd64.whl (110.9 MB)\n",
      "   ---------------------------------------- 0.0/110.9 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 17.8/110.9 MB 86.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 35.4/110.9 MB 86.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 53.2/110.9 MB 87.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 70.0/110.9 MB 86.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 89.4/110.9 MB 87.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 107.7/110.9 MB 86.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  110.9/110.9 MB 84.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 110.9/110.9 MB 75.5 MB/s  0:00:01\n",
      "Downloading networkx-3.6.1-py3-none-any.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 10.1 MB/s  0:00:00\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 2.6/6.3 MB 13.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.3/6.3 MB 15.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 14.6 MB/s  0:00:00\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 536.2/536.2 kB 14.2 MB/s  0:00:00\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading anyio-4.12.0-py3-none-any.whl (113 kB)\n",
      "Downloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading markupsafe-3.0.3-cp313-cp313-win_amd64.whl (15 kB)\n",
      "Downloading xxhash-3.6.0-cp313-cp313-win_amd64.whl (31 kB)\n",
      "Installing collected packages: mpmath, xxhash, urllib3, tqdm, sympy, safetensors, regex, pyyaml, pyarrow, propcache, networkx, multidict, MarkupSafe, idna, h11, fsspec, frozenlist, filelock, dill, charset_normalizer, certifi, attrs, aiohappyeyeballs, yarl, requests, multiprocess, jinja2, httpcore, anyio, aiosignal, torch, huggingface-hub, httpx, aiohttp, tokenizers, accelerate, transformers, datasets\n",
      "\n",
      "   ----------------------------------------  0/38 [mpmath]\n",
      "   ----------------------------------------  0/38 [mpmath]\n",
      "   -- -------------------------------------  2/38 [urllib3]\n",
      "   --- ------------------------------------  3/38 [tqdm]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ------- --------------------------------  7/38 [pyyaml]\n",
      "   -------- -------------------------------  8/38 [pyarrow]\n",
      "   -------- -------------------------------  8/38 [pyarrow]\n",
      "   -------- -------------------------------  8/38 [pyarrow]\n",
      "   -------- -------------------------------  8/38 [pyarrow]\n",
      "   -------- -------------------------------  8/38 [pyarrow]\n",
      "   -------- -------------------------------  8/38 [pyarrow]\n",
      "   -------- -------------------------------  8/38 [pyarrow]\n",
      "   -------- -------------------------------  8/38 [pyarrow]\n",
      "   ---------- ----------------------------- 10/38 [networkx]\n",
      "   ---------- ----------------------------- 10/38 [networkx]\n",
      "   ---------- ----------------------------- 10/38 [networkx]\n",
      "   ---------- ----------------------------- 10/38 [networkx]\n",
      "   ---------- ----------------------------- 10/38 [networkx]\n",
      "   ---------- ----------------------------- 10/38 [networkx]\n",
      "   ---------- ----------------------------- 10/38 [networkx]\n",
      "   ---------- ----------------------------- 10/38 [networkx]\n",
      "   ---------- ----------------------------- 10/38 [networkx]\n",
      "   ---------- ----------------------------- 10/38 [networkx]\n",
      "   ---------- ----------------------------- 10/38 [networkx]\n",
      "   ---------- ----------------------------- 10/38 [networkx]\n",
      "   ---------- ----------------------------- 10/38 [networkx]\n",
      "   ---------- ----------------------------- 10/38 [networkx]\n",
      "   ----------- ---------------------------- 11/38 [multidict]\n",
      "   -------------- ------------------------- 14/38 [h11]\n",
      "   --------------- ------------------------ 15/38 [fsspec]\n",
      "   ------------------ --------------------- 18/38 [dill]\n",
      "   -------------------- ------------------- 19/38 [charset_normalizer]\n",
      "   ------------------------ --------------- 23/38 [yarl]\n",
      "   -------------------------- ------------- 25/38 [multiprocess]\n",
      "   --------------------------- ------------ 26/38 [jinja2]\n",
      "   ---------------------------- ----------- 27/38 [httpcore]\n",
      "   ----------------------------- ---------- 28/38 [anyio]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   ------------------------------- -------- 30/38 [torch]\n",
      "   -------------------------------- ------- 31/38 [huggingface-hub]\n",
      "   -------------------------------- ------- 31/38 [huggingface-hub]\n",
      "   -------------------------------- ------- 31/38 [huggingface-hub]\n",
      "   -------------------------------- ------- 31/38 [huggingface-hub]\n",
      "   --------------------------------- ------ 32/38 [httpx]\n",
      "   ---------------------------------- ----- 33/38 [aiohttp]\n",
      "   ----------------------------------- ---- 34/38 [tokenizers]\n",
      "   ------------------------------------ --- 35/38 [accelerate]\n",
      "   ------------------------------------ --- 35/38 [accelerate]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   ------------------------------------- -- 36/38 [transformers]\n",
      "   -------------------------------------- - 37/38 [datasets]\n",
      "   -------------------------------------- - 37/38 [datasets]\n",
      "   -------------------------------------- - 37/38 [datasets]\n",
      "   ---------------------------------------- 38/38 [datasets]\n",
      "\n",
      "Successfully installed MarkupSafe-3.0.3 accelerate-1.12.0 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 anyio-4.12.0 attrs-25.4.0 certifi-2025.11.12 charset_normalizer-3.4.4 datasets-4.4.1 dill-0.4.0 filelock-3.20.0 frozenlist-1.8.0 fsspec-2025.10.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-0.36.0 idna-3.11 jinja2-3.1.6 mpmath-1.3.0 multidict-6.7.0 multiprocess-0.70.18 networkx-3.6.1 propcache-0.4.1 pyarrow-22.0.0 pyyaml-6.0.3 regex-2025.11.3 requests-2.32.5 safetensors-0.7.0 sympy-1.14.0 tokenizers-0.22.1 torch-2.9.1 tqdm-4.67.1 transformers-4.57.3 urllib3-2.6.1 xxhash-3.6.0 yarl-1.22.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install transformers datasets accelerate scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c779651",
   "metadata": {},
   "source": [
    "## BERT Baseline for Ekman Emotion Classification\n",
    "This notebook trains a baseline BERT model on the GoEmotions dataset mapped to Ekman emotions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b96c3c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce RTX 4080 SUPER\n"
     ]
    }
   ],
   "source": [
    "#check if cuda is available\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dcf0af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xiang\\miniconda3\\envs\\cis5300\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b9f202",
   "metadata": {},
   "source": [
    "### Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e300e550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 211225\n",
      "\n",
      "Label distribution:\n",
      "  anger: 30473 (14.4%)\n",
      "  disgust: 5301 (2.5%)\n",
      "  fear: 4515 (2.1%)\n",
      "  joy: 82938 (39.3%)\n",
      "  sadness: 19101 (9.0%)\n",
      "  surprise: 29282 (13.9%)\n",
      "  neutral: 55298 (26.2%)\n",
      "\n",
      "Train size: 168980\n",
      "Validation size: 21122\n",
      "Test size: 21123\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"data/goemotions_ekman.csv\")\n",
    "\n",
    "# Define emotion labels\n",
    "LABELS = ['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'neutral']\n",
    "NUM_LABELS = len(LABELS)\n",
    "\n",
    "# Check data distribution\n",
    "print(f\"Dataset size: {len(df)}\")\n",
    "print(\"\\nLabel distribution:\")\n",
    "for label in LABELS:\n",
    "    print(f\"  {label}: {df[label].sum()} ({df[label].mean()*100:.1f}%)\")\n",
    "\n",
    "# Split data\n",
    "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"\\nTrain size: {len(train_df)}\")\n",
    "print(f\"Validation size: {len(val_df)}\")\n",
    "print(f\"Test size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1993e4",
   "metadata": {},
   "source": [
    "### Create Dataset Class and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea28a6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batches: 10562\n",
      "Validation batches: 1321\n",
      "Test batches: 1321\n"
     ]
    }
   ],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=128):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.labels = LABELS\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.data.loc[idx, 'text'])\n",
    "        labels = self.data.loc[idx, self.labels].values.astype(float)\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(labels, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = EmotionDataset(train_df, tokenizer)\n",
    "val_dataset = EmotionDataset(val_df, tokenizer)\n",
    "test_dataset = EmotionDataset(test_df, tokenizer)\n",
    "\n",
    "# Create dataloaders\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaebd49",
   "metadata": {},
   "source": [
    "### Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20b09583",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on cuda\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained BERT model for multi-label classification\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=NUM_LABELS,\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "# Setup optimizer and scheduler\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 2e-5\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "print(f\"Model loaded on {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16783906",
   "metadata": {},
   "source": [
    "### Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b16efad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, device, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            \n",
    "            total_loss += outputs.loss.item()\n",
    "            \n",
    "            # Apply sigmoid and threshold\n",
    "            probs = torch.sigmoid(outputs.logits)\n",
    "            preds = (probs > threshold).float()\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    f1_micro = f1_score(all_labels, all_preds, average='micro')\n",
    "    f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
    "    \n",
    "    return {\n",
    "        'loss': total_loss / len(dataloader),\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'predictions': all_preds,\n",
    "        'labels': all_labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755f9108",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd26a0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Epoch 1/3\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10562/10562 [12:20<00:00, 14.27it/s]\n",
      "Training: 100%|██████████| 10562/10562 [12:20<00:00, 14.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1321/1321 [00:39<00:00, 33.75it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2684\n",
      "Validation F1 (micro): 0.5419\n",
      "Validation F1 (macro): 0.3977\n",
      "Saved best model!\n",
      "\n",
      "==================================================\n",
      "Epoch 2/3\n",
      "==================================================\n",
      "Saved best model!\n",
      "\n",
      "==================================================\n",
      "Epoch 2/3\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10562/10562 [11:54<00:00, 14.78it/s]\n",
      "Training: 100%|██████████| 10562/10562 [11:54<00:00, 14.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1321/1321 [00:39<00:00, 33.87it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2718\n",
      "Validation F1 (micro): 0.5649\n",
      "Validation F1 (macro): 0.4386\n",
      "Saved best model!\n",
      "\n",
      "==================================================\n",
      "Epoch 3/3\n",
      "==================================================\n",
      "Saved best model!\n",
      "\n",
      "==================================================\n",
      "Epoch 3/3\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10562/10562 [11:58<00:00, 14.70it/s]\n",
      "Training: 100%|██████████| 10562/10562 [11:58<00:00, 14.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1321/1321 [00:37<00:00, 34.80it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2785\n",
      "Validation F1 (micro): 0.5682\n",
      "Validation F1 (macro): 0.4564\n",
      "Saved best model!\n",
      "\n",
      "Best Validation F1 (macro): 0.4564\n",
      "Saved best model!\n",
      "\n",
      "Best Validation F1 (macro): 0.4564\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "best_f1 = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scheduler, device)\n",
    "    print(f\"Training Loss: {train_loss:.4f}\")\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    val_results = evaluate(model, val_loader, device)\n",
    "    print(f\"Validation Loss: {val_results['loss']:.4f}\")\n",
    "    print(f\"Validation F1 (micro): {val_results['f1_micro']:.4f}\")\n",
    "    print(f\"Validation F1 (macro): {val_results['f1_macro']:.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_results['f1_macro'] > best_f1:\n",
    "        best_f1 = val_results['f1_macro']\n",
    "        torch.save(model.state_dict(), 'best_bert_model.pt')\n",
    "        print(\"Saved best model!\")\n",
    "\n",
    "print(f\"\\nBest Validation F1 (macro): {best_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ed9578",
   "metadata": {},
   "source": [
    "### Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48c80d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1321/1321 [00:40<00:00, 32.95it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "TEST SET RESULTS\n",
      "==================================================\n",
      "Test Loss: 0.2779\n",
      "Test F1 (micro): 0.5665\n",
      "Test F1 (macro): 0.4603\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.55      0.36      0.43      3084\n",
      "     disgust       0.56      0.17      0.26       514\n",
      "        fear       0.57      0.33      0.41       473\n",
      "         joy       0.75      0.76      0.75      8232\n",
      "     sadness       0.58      0.41      0.48      1895\n",
      "    surprise       0.52      0.41      0.46      2894\n",
      "     neutral       0.59      0.33      0.42      5610\n",
      "\n",
      "   micro avg       0.65      0.50      0.57     22702\n",
      "   macro avg       0.59      0.39      0.46     22702\n",
      "weighted avg       0.63      0.50      0.55     22702\n",
      " samples avg       0.52      0.50      0.51     22702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load best model and evaluate on test set\n",
    "model.load_state_dict(torch.load('best_bert_model.pt'))\n",
    "\n",
    "test_results = evaluate(model, test_loader, device)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"TEST SET RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Test Loss: {test_results['loss']:.4f}\")\n",
    "print(f\"Test F1 (micro): {test_results['f1_micro']:.4f}\")\n",
    "print(f\"Test F1 (macro): {test_results['f1_macro']:.4f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(\n",
    "    test_results['labels'], \n",
    "    test_results['predictions'], \n",
    "    target_names=LABELS,\n",
    "    zero_division=0\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17965d96",
   "metadata": {},
   "source": [
    "### Test with Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "654697ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Predictions:\n",
      "============================================================\n",
      "\n",
      "Text: I'm so happy today! Everything is going great!\n",
      "Predicted: ['joy']\n",
      "Probabilities: anger:0.00, disgust:0.00, fear:0.00, joy:0.99, sadness:0.00, surprise:0.01, neutral:0.01\n",
      "\n",
      "Text: This makes me so angry, I can't believe it!\n",
      "Predicted: ['anger']\n",
      "Probabilities: anger:0.84, disgust:0.03, fear:0.01, joy:0.03, sadness:0.02, surprise:0.25, neutral:0.03\n",
      "\n",
      "Text: I'm really scared about what might happen.\n",
      "Predicted: ['fear']\n",
      "Probabilities: anger:0.02, disgust:0.02, fear:0.92, joy:0.09, sadness:0.04, surprise:0.08, neutral:0.03\n",
      "\n",
      "Text: That's disgusting, I hate it.\n",
      "Predicted: ['disgust']\n",
      "Probabilities: anger:0.35, disgust:0.90, fear:0.04, joy:0.03, sadness:0.10, surprise:0.03, neutral:0.02\n",
      "\n",
      "Text: I feel so sad and lonely.\n",
      "Predicted: ['sadness']\n",
      "Probabilities: anger:0.03, disgust:0.02, fear:0.05, joy:0.05, sadness:0.95, surprise:0.02, neutral:0.03\n",
      "\n",
      "Text: Wow, I didn't expect that at all!\n",
      "Predicted: ['surprise']\n",
      "Probabilities: anger:0.06, disgust:0.00, fear:0.00, joy:0.29, sadness:0.06, surprise:0.79, neutral:0.01\n"
     ]
    }
   ],
   "source": [
    "def predict_emotions(text, model, tokenizer, threshold=0.5):\n",
    "    \"\"\"Predict emotions for a single text.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=128,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=encoding['input_ids'].to(device),\n",
    "            attention_mask=encoding['attention_mask'].to(device)\n",
    "        )\n",
    "        probs = torch.sigmoid(outputs.logits).cpu().numpy()[0]\n",
    "    \n",
    "    results = {label: prob for label, prob in zip(LABELS, probs)}\n",
    "    predicted = [label for label, prob in results.items() if prob > threshold]\n",
    "    \n",
    "    return results, predicted\n",
    "\n",
    "# Test with sample texts\n",
    "sample_texts = [\n",
    "    \"I'm so happy today! Everything is going great!\",\n",
    "    \"This makes me so angry, I can't believe it!\",\n",
    "    \"I'm really scared about what might happen.\",\n",
    "    \"That's disgusting, I hate it.\",\n",
    "    \"I feel so sad and lonely.\",\n",
    "    \"Wow, I didn't expect that at all!\"\n",
    "]\n",
    "\n",
    "print(\"Sample Predictions:\")\n",
    "print(\"=\"*60)\n",
    "for text in sample_texts:\n",
    "    probs, predicted = predict_emotions(text, model, tokenizer)\n",
    "    print(f\"\\nText: {text}\")\n",
    "    print(f\"Predicted: {predicted if predicted else ['neutral']}\")\n",
    "    print(f\"Probabilities: {', '.join([f'{k}:{v:.2f}' for k, v in probs.items()])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cis5300",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
