{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "832d8cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (4.4.1)\n",
      "Requirement already satisfied: accelerate in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (1.12.0)\n",
      "Requirement already satisfied: scikit-learn in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (1.8.0)\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-6.33.2-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: transformers[sentencepiece] in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (4.57.3)\n",
      "Requirement already satisfied: filelock in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from transformers[sentencepiece]) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from transformers[sentencepiece]) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from transformers[sentencepiece]) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from transformers[sentencepiece]) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from transformers[sentencepiece]) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from transformers[sentencepiece]) (2025.11.3)\n",
      "Requirement already satisfied: requests in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from transformers[sentencepiece]) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from transformers[sentencepiece]) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from transformers[sentencepiece]) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from transformers[sentencepiece]) (4.67.1)\n",
      "Collecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece])\n",
      "  Downloading sentencepiece-0.2.1-cp314-cp314-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers[sentencepiece]) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers[sentencepiece]) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers[sentencepiece]) (1.2.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from httpx<1.0.0->datasets) (4.12.0)\n",
      "Requirement already satisfied: certifi in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: psutil in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from accelerate) (7.1.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from accelerate) (2.9.1+cu130)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.3.0 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from requests->transformers[sentencepiece]) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from requests->transformers[sentencepiece]) (2.6.2)\n",
      "Requirement already satisfied: setuptools in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from torch>=2.0.0->accelerate) (70.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from torch>=2.0.0->accelerate) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc==13.0.48 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from torch>=2.0.0->accelerate) (13.0.48)\n",
      "Requirement already satisfied: nvidia-cuda-runtime==13.0.48 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from torch>=2.0.0->accelerate) (13.0.48)\n",
      "Requirement already satisfied: nvidia-cuda-cupti==13.0.48 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from torch>=2.0.0->accelerate) (13.0.48)\n",
      "Requirement already satisfied: nvidia-cudnn-cu13==9.13.0.50 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from torch>=2.0.0->accelerate) (9.13.0.50)\n",
      "Requirement already satisfied: nvidia-cublas==13.0.0.19 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from torch>=2.0.0->accelerate) (13.0.0.19)\n",
      "Requirement already satisfied: nvidia-cufft==12.0.0.15 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from torch>=2.0.0->accelerate) (12.0.0.15)\n",
      "Requirement already satisfied: nvidia-curand==10.4.0.35 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from torch>=2.0.0->accelerate) (10.4.0.35)\n",
      "Requirement already satisfied: nvidia-cusolver==12.0.3.29 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from torch>=2.0.0->accelerate) (12.0.3.29)\n",
      "Requirement already satisfied: nvidia-cusparse==12.6.2.49 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from torch>=2.0.0->accelerate) (12.6.2.49)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu13==0.8.0 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from torch>=2.0.0->accelerate) (0.8.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu13==2.27.7 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from torch>=2.0.0->accelerate) (2.27.7)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu13==3.3.24 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from torch>=2.0.0->accelerate) (3.3.24)\n",
      "Requirement already satisfied: nvidia-nvtx==13.0.39 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from torch>=2.0.0->accelerate) (13.0.39)\n",
      "Requirement already satisfied: nvidia-nvjitlink==13.0.39 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from torch>=2.0.0->accelerate) (13.0.39)\n",
      "Requirement already satisfied: nvidia-cufile==1.15.0.42 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from torch>=2.0.0->accelerate) (1.15.0.42)\n",
      "Requirement already satisfied: triton==3.5.1 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from torch>=2.0.0->accelerate) (3.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from pandas->datasets) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading protobuf-6.33.2-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
      "Downloading sentencepiece-0.2.1-cp314-cp314-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece, protobuf\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [protobuf]1/2\u001b[0m [protobuf]\n",
      "\u001b[1A\u001b[2KSuccessfully installed protobuf-6.33.2 sentencepiece-0.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (DeBERTa requires sentencepiece and protobuf)\n",
    "%pip install transformers[sentencepiece] datasets accelerate scikit-learn protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fad336cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b57e2d",
   "metadata": {},
   "source": [
    "### Load Data and Define Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "849cb1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 43410, Val: 5426, Test: 5427\n"
     ]
    }
   ],
   "source": [
    "# Load the GoEmotions dataset\n",
    "dataset = load_dataset(\"google-research-datasets/go_emotions\", \"simplified\")\n",
    "\n",
    "LABELS = [\n",
    "    'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring',\n",
    "    'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval',\n",
    "    'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief',\n",
    "    'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization',\n",
    "    'relief', 'remorse', 'sadness', 'surprise', 'neutral'\n",
    "]\n",
    "NUM_LABELS = len(LABELS)\n",
    "\n",
    "def convert_to_df(split):\n",
    "    data = dataset[split]\n",
    "    rows = []\n",
    "    for i in range(len(data)):\n",
    "        text = data[i]['text']\n",
    "        label_ids = data[i]['labels']\n",
    "        label_vec = [1 if j in label_ids else 0 for j in range(NUM_LABELS)]\n",
    "        rows.append([text] + label_vec)\n",
    "    return pd.DataFrame(rows, columns=['text'] + LABELS)\n",
    "\n",
    "train_df = convert_to_df('train')\n",
    "val_df = convert_to_df('validation')\n",
    "test_df = convert_to_df('test')\n",
    "\n",
    "print(f\"Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e6ae2a",
   "metadata": {},
   "source": [
    "### Initialize DeBERTa Tokenizer and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13933afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages/transformers/convert_slow_tokenizer.py:566: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Use DeBERTa v3 base tokenizer\n",
    "MODEL_NAME = \"microsoft/deberta-v3-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=128):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.labels = LABELS\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.data.loc[idx, 'text'])\n",
    "        labels = self.data.loc[idx, self.labels].values.astype(float)\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(labels, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "train_dataset = EmotionDataset(train_df, tokenizer)\n",
    "val_dataset = EmotionDataset(val_df, tokenizer)\n",
    "test_dataset = EmotionDataset(test_df, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b82126",
   "metadata": {},
   "source": [
    "### Initialize DeBERTa Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0dbab9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model microsoft/deberta-v3-base loaded on cuda\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=NUM_LABELS,\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "EPOCHS = 4  # DeBERTa often benefits from slightly longer training\n",
    "LEARNING_RATE = 2e-5\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=500, # Slight warmup\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "print(f\"Model {MODEL_NAME} loaded on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4958c674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, device, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            total_loss += outputs.loss.item()\n",
    "            \n",
    "            probs = torch.sigmoid(outputs.logits)\n",
    "            preds = (probs > threshold).float()\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    f1_micro = f1_score(all_labels, all_preds, average='micro')\n",
    "    f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
    "    \n",
    "    return {\n",
    "        'loss': total_loss / len(dataloader),\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'predictions': all_preds,\n",
    "        'labels': all_labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d434ab7",
   "metadata": {},
   "source": [
    "### Train DeBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f2218f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2714/2714 [05:37<00:00,  8.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 340/340 [00:16<00:00, 21.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0936\n",
      "Validation F1 (micro): 0.5229\n",
      "Validation F1 (macro): 0.2893\n",
      "Saved best model!\n",
      "\n",
      "Epoch 2/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2714/2714 [05:20<00:00,  8.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 340/340 [00:13<00:00, 25.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0852\n",
      "Validation F1 (micro): 0.5766\n",
      "Validation F1 (macro): 0.3938\n",
      "Saved best model!\n",
      "\n",
      "Epoch 3/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2714/2714 [05:22<00:00,  8.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 340/340 [00:15<00:00, 22.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0858\n",
      "Validation F1 (micro): 0.5755\n",
      "Validation F1 (macro): 0.4336\n",
      "Saved best model!\n",
      "\n",
      "Epoch 4/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2714/2714 [06:01<00:00,  7.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 340/340 [00:16<00:00, 20.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0850\n",
      "Validation F1 (micro): 0.5880\n",
      "Validation F1 (macro): 0.4568\n",
      "Saved best model!\n",
      "\n",
      "Best Validation F1 (macro): 0.4568\n"
     ]
    }
   ],
   "source": [
    "best_f1 = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n",
    "    \n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scheduler, device)\n",
    "    print(f\"Training Loss: {train_loss:.4f}\")\n",
    "    \n",
    "    val_results = evaluate(model, val_loader, device)\n",
    "    print(f\"Validation Loss: {val_results['loss']:.4f}\")\n",
    "    print(f\"Validation F1 (micro): {val_results['f1_micro']:.4f}\")\n",
    "    print(f\"Validation F1 (macro): {val_results['f1_macro']:.4f}\")\n",
    "    \n",
    "    if val_results['f1_macro'] > best_f1:\n",
    "        best_f1 = val_results['f1_macro']\n",
    "        torch.save(model.state_dict(), 'best_deberta_model.pt')\n",
    "        print(\"Saved best model!\")\n",
    "\n",
    "print(f\"\\nBest Validation F1 (macro): {best_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f591128",
   "metadata": {},
   "source": [
    "### Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3da6609a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 340/340 [00:15<00:00, 21.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "DEBERTA TEST RESULTS\n",
      "==================================================\n",
      "Test F1 (micro): 0.5908\n",
      "Test F1 (macro): 0.4559\n",
      "\n",
      "Detailed Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.70      0.72      0.71       504\n",
      "     amusement       0.77      0.90      0.83       264\n",
      "         anger       0.54      0.46      0.50       198\n",
      "     annoyance       0.56      0.20      0.29       320\n",
      "      approval       0.56      0.36      0.44       351\n",
      "        caring       0.53      0.39      0.44       135\n",
      "     confusion       0.54      0.37      0.44       153\n",
      "     curiosity       0.50      0.54      0.52       284\n",
      "        desire       0.72      0.37      0.49        83\n",
      "disappointment       0.53      0.12      0.19       151\n",
      "   disapproval       0.46      0.37      0.41       267\n",
      "       disgust       0.60      0.40      0.48       123\n",
      " embarrassment       0.71      0.32      0.44        37\n",
      "    excitement       0.50      0.34      0.40       103\n",
      "          fear       0.60      0.72      0.65        78\n",
      "     gratitude       0.94      0.91      0.92       352\n",
      "         grief       0.00      0.00      0.00         6\n",
      "           joy       0.67      0.60      0.63       161\n",
      "          love       0.78      0.85      0.81       238\n",
      "   nervousness       0.00      0.00      0.00        23\n",
      "      optimism       0.67      0.51      0.57       186\n",
      "         pride       0.00      0.00      0.00        16\n",
      "   realization       0.52      0.11      0.18       145\n",
      "        relief       0.00      0.00      0.00        11\n",
      "       remorse       0.63      0.77      0.69        56\n",
      "       sadness       0.57      0.51      0.54       156\n",
      "      surprise       0.54      0.51      0.53       141\n",
      "       neutral       0.75      0.54      0.63      1787\n",
      "\n",
      "     micro avg       0.67      0.53      0.59      6329\n",
      "     macro avg       0.53      0.42      0.46      6329\n",
      "  weighted avg       0.66      0.53      0.57      6329\n",
      "   samples avg       0.58      0.55      0.55      6329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best_deberta_model.pt'))\n",
    "test_results = evaluate(model, test_loader, device)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"DEBERTA TEST RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Test F1 (micro): {test_results['f1_micro']:.4f}\")\n",
    "print(f\"Test F1 (macro): {test_results['f1_macro']:.4f}\")\n",
    "\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(\n",
    "    test_results['labels'], \n",
    "    test_results['predictions'], \n",
    "    target_names=LABELS,\n",
    "    zero_division=0\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53e96bb",
   "metadata": {},
   "source": [
    "## Domain Adaptation: Presidential Speeches\n",
    "Fine-tune the best DeBERTa model on the presidential speeches dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7be28595",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import train test split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08dbd799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presidential Dataset Shape: (995, 67)\n",
      "Using text column: speech\n"
     ]
    }
   ],
   "source": [
    "# Load Presidential Data\n",
    "pres_df = pd.read_csv(\"data/presidential_speeches_goemotions_labeled.csv\")\n",
    "print(f\"Presidential Dataset Shape: {pres_df.shape}\")\n",
    "\n",
    "# Identify text column\n",
    "text_col = None\n",
    "for col in ['speech', 'Speech', 'transcript', 'Transcript', 'text', 'Text', 'content']:\n",
    "    if col in pres_df.columns:\n",
    "        text_col = col\n",
    "        break\n",
    "\n",
    "if text_col is None:\n",
    "    raise ValueError(f\"Could not find text column. Available columns: {pres_df.columns.tolist()}\")\n",
    "\n",
    "print(f\"Using text column: {text_col}\")\n",
    "\n",
    "# Train-test split\n",
    "pres_train_df, pres_test_df = train_test_split(pres_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define Dataset class for Presidential data\n",
    "class PresidentialDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, text_col, max_length=256):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.text_col = text_col\n",
    "        self.labels = LABELS\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.data.loc[idx, self.text_col])\n",
    "        if pd.isna(text):\n",
    "            text = \"\"\n",
    "        labels = self.data.loc[idx, self.labels].values.astype(float)\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(labels, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "# Create DataLoaders\n",
    "pres_train_dataset = PresidentialDataset(pres_train_df, tokenizer, text_col)\n",
    "pres_test_dataset = PresidentialDataset(pres_test_df, tokenizer, text_col)\n",
    "\n",
    "pres_train_loader = DataLoader(pres_train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "pres_test_loader = DataLoader(pres_test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8778bc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning DeBERTa on presidential data for 3 epochs...\n",
      "\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:14<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  4.84it/s]\n",
      "/home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0527\n",
      "Test F1 (micro): 0.7169\n",
      "Test F1 (macro): 0.0404\n",
      "Saved best presidential model!\n",
      "\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:13<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  4.61it/s]\n",
      "/home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0528\n",
      "Test F1 (micro): 0.6883\n",
      "Test F1 (macro): 0.0394\n",
      "\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:14<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0524\n",
      "Test F1 (micro): 0.6868\n",
      "Test F1 (macro): 0.0394\n",
      "\n",
      "Best Presidential Test F1 (macro): 0.0404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Load the best DeBERTa model\n",
    "model.load_state_dict(torch.load('best_deberta_model.pt'))\n",
    "model.to(device)\n",
    "\n",
    "# Fine-tuning parameters\n",
    "FINE_TUNE_LR = 1e-5\n",
    "FINE_TUNE_EPOCHS = 3\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=FINE_TUNE_LR, weight_decay=0.01)\n",
    "total_steps = len(pres_train_loader) * FINE_TUNE_EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "print(f\"Fine-tuning DeBERTa on presidential data for {FINE_TUNE_EPOCHS} epochs...\")\n",
    "\n",
    "best_pres_f1 = 0\n",
    "\n",
    "for epoch in range(FINE_TUNE_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{FINE_TUNE_EPOCHS}\")\n",
    "    \n",
    "    train_loss = train_epoch(model, pres_train_loader, optimizer, scheduler, device)\n",
    "    print(f\"Training Loss: {train_loss:.4f}\")\n",
    "    \n",
    "    val_results = evaluate(model, pres_test_loader, device)\n",
    "    print(f\"Test Loss: {val_results['loss']:.4f}\")\n",
    "    print(f\"Test F1 (micro): {val_results['f1_micro']:.4f}\")\n",
    "    print(f\"Test F1 (macro): {val_results['f1_macro']:.4f}\")\n",
    "    \n",
    "    if val_results['f1_macro'] > best_pres_f1:\n",
    "        best_pres_f1 = val_results['f1_macro']\n",
    "        torch.save(model.state_dict(), 'best_presidential_deberta_model.pt')\n",
    "        print(\"Saved best presidential model!\")\n",
    "\n",
    "print(f\"\\nBest Presidential Test F1 (macro): {best_pres_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1f5d50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FINAL PRESIDENTIAL DEBERTA MODEL RESULTS\n",
      "============================================================\n",
      "Test Loss: 0.0527\n",
      "Test F1 (micro): 0.7169\n",
      "Test F1 (macro): 0.0404\n",
      "\n",
      "Detailed Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.00      0.00      0.00         3\n",
      "     amusement       0.00      0.00      0.00         0\n",
      "         anger       0.00      0.00      0.00         0\n",
      "     annoyance       0.00      0.00      0.00         0\n",
      "      approval       0.00      0.00      0.00        36\n",
      "        caring       0.00      0.00      0.00         1\n",
      "     confusion       0.00      0.00      0.00         0\n",
      "     curiosity       0.00      0.00      0.00         1\n",
      "        desire       0.00      0.00      0.00         2\n",
      "disappointment       0.00      0.00      0.00         0\n",
      "   disapproval       0.00      0.00      0.00         0\n",
      "       disgust       0.00      0.00      0.00         0\n",
      " embarrassment       0.00      0.00      0.00         0\n",
      "    excitement       0.00      0.00      0.00         0\n",
      "          fear       0.00      0.00      0.00         0\n",
      "     gratitude       0.67      0.17      0.27        12\n",
      "         grief       0.00      0.00      0.00         0\n",
      "           joy       0.00      0.00      0.00         0\n",
      "          love       0.00      0.00      0.00         0\n",
      "   nervousness       0.00      0.00      0.00         0\n",
      "      optimism       0.00      0.00      0.00        12\n",
      "         pride       0.00      0.00      0.00         0\n",
      "   realization       0.00      0.00      0.00         0\n",
      "        relief       0.00      0.00      0.00         0\n",
      "       remorse       0.00      0.00      0.00         0\n",
      "       sadness       0.00      0.00      0.00         0\n",
      "      surprise       0.00      0.00      0.00         0\n",
      "       neutral       0.82      0.91      0.86       149\n",
      "\n",
      "     micro avg       0.82      0.64      0.72       216\n",
      "     macro avg       0.05      0.04      0.04       216\n",
      "  weighted avg       0.60      0.64      0.61       216\n",
      "   samples avg       0.69      0.63      0.65       216\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/xiang/miniconda3/envs/nlp/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Load best presidential model\n",
    "model.load_state_dict(torch.load('best_presidential_deberta_model.pt'))\n",
    "\n",
    "final_results = evaluate(model, pres_test_loader, device)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"FINAL PRESIDENTIAL DEBERTA MODEL RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Test Loss: {final_results['loss']:.4f}\")\n",
    "print(f\"Test F1 (micro): {final_results['f1_micro']:.4f}\")\n",
    "print(f\"Test F1 (macro): {final_results['f1_macro']:.4f}\")\n",
    "\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(\n",
    "    final_results['labels'], \n",
    "    final_results['predictions'], \n",
    "    target_names=LABELS,\n",
    "    zero_division=0\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
